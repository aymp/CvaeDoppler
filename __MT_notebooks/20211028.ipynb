{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **モデル**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# CWT\n",
    "import math\n",
    "import pycwt\n",
    "\n",
    "# 自作関数\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import sig_proc\n",
    "peak_detect = __import__('2_peak_detect') # 先頭が数字のファイルなので素直にimportできない　非推奨だがこのやり方ならOK\n",
    "\n",
    "def zscore(x,axis=None):\n",
    "    x_mean = x.mean(axis=axis, keepdims=True)\n",
    "    x_std = np.std(x, axis=axis, keepdims=True)\n",
    "    z_score = (x-x_mean)/x_std\n",
    "    return z_score\n",
    "    \n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- q(z|x,y) : (32, 100) ⇒ (16, 50) ⇒ (8, 25)\n",
      "- q(y|x)   : (32, 100) ⇒ (33, 101) ⇒ (16, 50) ⇒ (17, 51) ⇒ (8, 25)\n",
      "- p(x|z)   : (8, 25) ⇒ (16, 50) ⇒ (32, 100)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# CONV2D->https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "def Conv2d_OutputShape(in_size,kernel_size,stride=(1,1),padding=(0,0),dilation=(1,1)):\n",
    "    H_in = in_size[0]\n",
    "    W_in = in_size[1]\n",
    "    H_out = math.floor((H_in+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
    "    W_out = math.floor((W_in+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
    "    return (H_out,W_out)\n",
    "\n",
    "# MAXPOOL2D (CONV2Dと同じ式でした......)->https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
    "def MaxPool2d_OutputShape(in_size,kernel_size,stride=None,padding=(0,0),dilation=(1,1)):\n",
    "    if stride == None:\n",
    "        stride = kernel_size\n",
    "    H_in = in_size[0]\n",
    "    W_in = in_size[1]\n",
    "    H_out = math.floor((H_in+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
    "    W_out = math.floor((W_in+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
    "    return (H_out,W_out)\n",
    "\n",
    "# CONVTRANSPOSE2D->https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html\n",
    "def ConvTranspose2d_OutputShape(in_size,kernel_size,stride=(1,1),padding=(0,0),output_padding=(0,0),dilation=(1,1)):\n",
    "    H_in = in_size[0]\n",
    "    W_in = in_size[1]\n",
    "    H_out = (H_in-1)*stride[0]-2*padding[0]+dilation[0]*(kernel_size[0]-1)+output_padding[0]+1\n",
    "    W_out = (W_in-1)*stride[1]-2*padding[1]+dilation[1]*(kernel_size[1]-1)+output_padding[1]+1\n",
    "    return (H_out,W_out)\n",
    "\n",
    "# q(z|x, y)\n",
    "in_size = (32,100)\n",
    "out_size1 = Conv2d_OutputShape(in_size,(4,4),stride=(2,2),padding=(1,1))\n",
    "out_size2 = Conv2d_OutputShape(out_size1,(4,4),stride=(2,2),padding=(1,1))\n",
    "print(f\"- q(z|x,y) : {in_size} ⇒ {out_size1} ⇒ {out_size2}\")\n",
    "\n",
    "# q(y|x)\n",
    "out_size3 = Conv2d_OutputShape(in_size,(4,4),padding=(2,2))\n",
    "out_size4 = MaxPool2d_OutputShape(out_size3,(2,2))\n",
    "out_size5 = Conv2d_OutputShape(out_size4,(4,4),padding=(2,2))\n",
    "out_size6 = MaxPool2d_OutputShape(out_size5,(2,2))\n",
    "print(f\"- q(y|x)   : {in_size} ⇒ {out_size3} ⇒ {out_size4} ⇒ {out_size5} ⇒ {out_size6}\")\n",
    "\n",
    "# p(x|z)\n",
    "in_size_d = (in_size[0]//4, in_size[1]//4)\n",
    "out_size7 = ConvTranspose2d_OutputShape(in_size_d,(4,4),stride=(2,2),padding=(1,1))\n",
    "out_size8 = ConvTranspose2d_OutputShape(out_size7,(4,4),stride=(2,2),padding=(1,1))\n",
    "print(f\"- p(x|z)   : {in_size_d} ⇒ {out_size7} ⇒ {out_size8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_HEIGHT = 32\n",
    "INPUT_WIDTH = 100\n",
    "\n",
    "# q(z|x, y)\n",
    "class Qz_xy(nn.Module):\n",
    "    def __init__(self, z_dim=2, y_dim=10):\n",
    "        super(Qz_xy, self).__init__()\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        # encode\n",
    "        self.conv_e = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1),  # (32,100) ⇒ (16, 50)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # (16, 50) ⇒ (8, 25)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear((INPUT_HEIGHT//4) * (INPUT_WIDTH//4)* 128,  40),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear((INPUT_HEIGHT//4) * (INPUT_WIDTH//4)* 128,  y_dim),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(40+y_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 2*self.z_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = self.conv_e(x)\n",
    "        x = x.view(-1,(INPUT_HEIGHT//4) * (INPUT_WIDTH//4)* 128)\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc2(x)\n",
    "        x = torch.cat([x1, x2*y], dim=1)\n",
    "        x = self.fc(x)\n",
    "        mu = x[:, :self.z_dim]\n",
    "        logvar = x[:, self.z_dim:]\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        self.mu = mu\n",
    "        self.logvar = logvar\n",
    "        return z\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.new(std.size()).normal_()\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "\n",
    "# q(y|x)\n",
    "class Qy_x(nn.Module):\n",
    "    def __init__(self, y_dim=10):\n",
    "        super(Qy_x, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=4,padding=2),   # (32,100) ⇒ (33, 101)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)) # (33, 101) ⇒ (16, 50)\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=4, padding=2), # (16, 50) ⇒ (17, 51)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)) # (17, 51) ⇒ (8, 25)\n",
    "\n",
    "        self.fc =  nn.Sequential(\n",
    "            nn.Linear(-(-INPUT_HEIGHT//4) * -(-INPUT_WIDTH//4)* 128, 256),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, y_dim),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1(x)\n",
    "        c2 = self.conv2(c1)\n",
    "        c2_flat = c2.view(c2.size(0), -1)\n",
    "        out = self.fc(c2_flat)\n",
    "        return out\n",
    "\n",
    "# p(z|y)\n",
    "class Pz_y(nn.Module):\n",
    "    def __init__(self, z_dim=2, y_dim=10):\n",
    "        super(Pz_y, self).__init__()\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        # encode\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(y_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 2*self.z_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, y):\n",
    "        x = self.fc(y)\n",
    "        mu = x[:, :self.z_dim]\n",
    "        logvar = x[:, self.z_dim:]\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        self.mu = mu\n",
    "        self.logvar = logvar\n",
    "        return z\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.new(std.size()).normal_()\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def sample(self, y):\n",
    "        x = self.fc(y)\n",
    "        mu = x[:, :self.z_dim]\n",
    "        logvar = x[:, self.z_dim:]\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = std.new(std.size()).normal_()\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "# p(x|z)\n",
    "class Px_z(nn.Module):\n",
    "    def __init__(self, z_dim=2):\n",
    "        super(Px_z, self).__init__()\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        # decode\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.z_dim, 40),\n",
    "        )\n",
    "\n",
    "        self.fc_d = nn.Sequential(\n",
    "            nn.Linear(40, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024,(INPUT_HEIGHT//4) * (INPUT_WIDTH//4)* 128),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.conv_d = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1), # (8, 25) ⇒ (16, 50)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1), # (16, 50) ⇒ (32, 100) 元通り！\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.fc(z)\n",
    "        h = self.fc_d(z)\n",
    "        h = h.view(-1, 128, (INPUT_HEIGHT//4), (INPUT_WIDTH//4))\n",
    "        #print(h.shape)\n",
    "        return self.conv_d(h)\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data, label, datatime_idx, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = data\n",
    "        self.data_num = len(data)\n",
    "        self.label = label\n",
    "        self.datatime_idx = datatime_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_num\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform:\n",
    "            # print(self.data.shape)\n",
    "            # print(self.data[idx].shape)\n",
    "            out_data = self.transform(self.data[idx])\n",
    "            out_label = int(self.label[idx])\n",
    "            out_datatime_idx = int(self.datatime_idx[idx])\n",
    "        else:\n",
    "            out_data = self.data[idx]\n",
    "            out_label =  self.label[idx]\n",
    "            out_datatime_idx = self.datatime_idx[idx]\n",
    "\n",
    "        return out_data, out_label, out_datatime_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全員のデータ対象に処理\n",
    "ファイルリストに注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.7262742772967\n"
     ]
    }
   ],
   "source": [
    "# パラメータ\n",
    "fs = 125\n",
    "lpf_fp = 30\n",
    "lpf_fs = 32\n",
    "hpf_fp = 5\n",
    "hpf_fs = 3\n",
    "thinning_num = 4\n",
    "\n",
    "dt = 1/fs\n",
    "pre_sec = 0.5\n",
    "post_sec = 0.3\n",
    "pre_sample_num = int(pre_sec*fs)\n",
    "post_sample_num = int(post_sec*fs)+1\n",
    "N = pre_sample_num + post_sample_num # サンプル点数\n",
    "time_array = np.arange(0,N)*dt # グラフ横軸（時間）\n",
    "\n",
    "mother = pycwt.Morlet(6)\n",
    "s0 = 2*dt # ウェーブレットの最小スケール。デフォルト値2dt。\n",
    "dj = 1/12 # 離散スケールの間隔。デフォルト値1/12。\n",
    "J =(math.log2(N * dt / s0))/dj # スケールの範囲s0からs0*2**(J*dj)までで、計(J+1)の尺度。\n",
    "print(J)\n",
    "\n",
    "# ファイルリスト読み込み\n",
    "filtered_filelist = '../0_FileList/8_Raw.txt'\n",
    "filelist_fp = codecs.open(filtered_filelist, 'r')\n",
    "\n",
    "# ファイル読み込み\n",
    "for idx, filename in enumerate(filelist_fp):\n",
    "    split_fpdata = filename.rstrip('\\r\\n').split(',')\n",
    "    fname = split_fpdata[0]\n",
    "    fname = '../'+fname\n",
    "    wave_fp = codecs.open(fname, 'r')\n",
    "\n",
    "# ----- csvから2次元listへ\n",
    "    times = []\n",
    "    ch = []\n",
    "    for i in range(7):\n",
    "        ch.append([])\n",
    "    for idx2, line in enumerate(wave_fp):\n",
    "        split_data = line.rstrip('\\r\\n').split(',')\n",
    "        times.append(idx2)\n",
    "        for i in range(7):\n",
    "            ch[i].append(int(float(split_data[i])))\n",
    "    wave_fp.close()\n",
    "\n",
    "    ################################################################################\n",
    "    #                                フィルタ                                      #\n",
    "    ################################################################################\n",
    "\n",
    "    # PPGのフィルタは多分これで確定でよい\n",
    "    ppg = sig_proc.lpf(ch[0], 500, fp=5, fs=10)[::thinning_num]  # PPG\n",
    "\n",
    "    i_1st = ch[1]\n",
    "    i_2nd = ch[2]\n",
    "    q_1st = ch[3]\n",
    "    q_2nd = ch[4]\n",
    "    iq_diff_1st = [i-q for (i,q) in zip(i_1st, q_1st)]\n",
    "    iq_diff_2nd = [i-q for (i,q) in zip(i_2nd, q_2nd)]\n",
    "\n",
    "    # フィルタをかける\n",
    "    i_1st = sig_proc.hpf(sig_proc.lpf(i_1st,500,fp=lpf_fp,fs=lpf_fs),500,fp=hpf_fp,fs=hpf_fs)[::thinning_num]\n",
    "    i_2nd = sig_proc.hpf(sig_proc.lpf(i_2nd,500,fp=lpf_fp,fs=lpf_fs),500,fp=hpf_fp,fs=hpf_fs)[::thinning_num]\n",
    "    q_1st = sig_proc.hpf(sig_proc.lpf(q_1st,500,fp=lpf_fp,fs=lpf_fs),500,fp=hpf_fp,fs=hpf_fs)[::thinning_num]\n",
    "    q_2nd = sig_proc.hpf(sig_proc.lpf(q_2nd,500,fp=lpf_fp,fs=lpf_fs),500,fp=hpf_fp,fs=hpf_fs)[::thinning_num]\n",
    "    iq_diff_1st = sig_proc.hpf(sig_proc.lpf(iq_diff_1st,500,fp=lpf_fp,fs=lpf_fs),500,fp=hpf_fp,fs=hpf_fs)[::thinning_num]\n",
    "    iq_diff_2nd = sig_proc.hpf(sig_proc.lpf(iq_diff_2nd,500,fp=lpf_fp,fs=lpf_fs),500,fp=hpf_fp,fs=hpf_fs)[::thinning_num]\n",
    "\n",
    "    # 呼吸ありデータ\n",
    "    X_LIM_MIN = int(split_fpdata[1])/thinning_num\n",
    "    X_LIM_MIN = int(X_LIM_MIN)\n",
    "    X_LIM_MAX = X_LIM_MIN+30000/thinning_num #そこから60sは通常の呼吸\n",
    "    X_LIM_MAX = int(X_LIM_MAX)\n",
    "\n",
    "    chnp = [] \n",
    "    chnp.append(np.array(ppg)[X_LIM_MIN:X_LIM_MAX])\n",
    "    chnp.append(np.array(i_1st)[X_LIM_MIN:X_LIM_MAX])\n",
    "    chnp.append(np.array(i_2nd)[X_LIM_MIN:X_LIM_MAX])\n",
    "    chnp.append(np.array(q_1st)[X_LIM_MIN:X_LIM_MAX])\n",
    "    chnp.append(np.array(q_2nd)[X_LIM_MIN:X_LIM_MAX])\n",
    "    chnp.append(np.array(iq_diff_1st)[X_LIM_MIN:X_LIM_MAX])\n",
    "    chnp.append(np.array(iq_diff_2nd)[X_LIM_MIN:X_LIM_MAX])\n",
    "    data_b = np.vstack([chnp[0], chnp[1], chnp[2], chnp[3], chnp[4], chnp[5], chnp[6]]) # 必要になればこれファイル出力すればOK\n",
    "    \n",
    "\n",
    "    # 呼吸なしデータ\n",
    "    if int(split_fpdata[2]) == -1:\n",
    "        X_LIM_MAX = -1\n",
    "    else:\n",
    "        X_LIM_MAX = int(split_fpdata[2])/thinning_num\n",
    "        X_LIM_MAX = int(X_LIM_MAX)\n",
    "    X_LIM_MIN = X_LIM_MAX - 5000/thinning_num\n",
    "    X_LIM_MIN = int(X_LIM_MIN)\n",
    "\n",
    "    chnp = []\n",
    "    chnp.append(np.array(ppg)[X_LIM_MIN:X_LIM_MAX])\n",
    "    chnp.append(np.array(i_1st)[X_LIM_MIN:X_LIM_MAX])\n",
    "    chnp.append(np.array(i_2nd)[X_LIM_MIN:X_LIM_MAX])\n",
    "    chnp.append(np.array(q_1st)[X_LIM_MIN:X_LIM_MAX])\n",
    "    chnp.append(np.array(q_2nd)[X_LIM_MIN:X_LIM_MAX])\n",
    "    chnp.append(np.array(iq_diff_1st)[X_LIM_MIN:X_LIM_MAX])\n",
    "    chnp.append(np.array(iq_diff_2nd)[X_LIM_MIN:X_LIM_MAX])\n",
    "    data_wob = np.vstack([chnp[0], chnp[1], chnp[2], chnp[3], chnp[4], chnp[5], chnp[6]])\n",
    "\n",
    "    ################################################################################\n",
    "    #                                　分割　                                      #\n",
    "    ################################################################################\n",
    "    # 一旦、呼吸なしデータだけを対象にして考える\n",
    "    ppg = data_wob[0]\n",
    "    len_data = data_wob.shape[1]\n",
    "\n",
    "# ----- 時系列探索でPPGピーク検出＆分割\n",
    "    peak_times, peak_vals = sig_proc.peak_search(sig_proc.min_max(ppg), fs)\n",
    "    # 必要な部分だけ集めたデータdata_dist。あとから一拍ずつ分割。\n",
    "    data_dist, npeaks, len_per_one, peak_times, peak_vals = peak_detect.data_distribution(data_wob, len_data, peak_times, peak_vals, pre_sample_num, post_sample_num)\n",
    "    \n",
    "    npeaks = data_dist.shape[0]\n",
    "\n",
    "    fig = plt.figure(figsize=(18,10))\n",
    "    \n",
    "    # 時系列波形\n",
    "    for peak_idx in range(npeaks):\n",
    "        if peak_idx >= 9:\n",
    "            continue\n",
    "\n",
    "        # 呼吸なしデータ可視化\n",
    "        doppler_data = data_dist[peak_idx][6]\n",
    "        ppg_data = data_dist[peak_idx][0]\n",
    "\n",
    "        ax1 = fig.add_subplot(3,3,peak_idx+1)\n",
    "        ax1.plot(time_array, doppler_data, color='tab:blue', lw=5)\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(time_array, ppg_data, color='tab:orange')\n",
    "    #fig.tight_layout()\n",
    "    fig.suptitle(fname, fontsize=30)\n",
    "    plt.show()\n",
    "\n",
    "    # CWT\n",
    "    fig = plt.figure(figsize=(18,10))\n",
    "    for peak_idx in range(npeaks):\n",
    "        if peak_idx >= 9:\n",
    "            continue\n",
    "\n",
    "        doppler_data = data_dist[peak_idx][6]\n",
    "        wave, _scales, freqs, _coi, _fft, _fftfreqs = pycwt.cwt(doppler_data, dt, dj, s0, J, mother)\n",
    "\n",
    "        wave = wave[12:44,:]\n",
    "        freqs = freqs[12:44]\n",
    "\n",
    "        #wave = np.log(wave)\n",
    "        #wave = sig_proc.min_max(wave) # 0-1正規化\n",
    "        #wave = zscore(wave)\n",
    "        \n",
    "        ax = fig.add_subplot(3,3,peak_idx+1)\n",
    "        ax.pcolormesh(time_array, freqs, np.abs(wave), vmin=0, shading='auto')\n",
    "        ax.set_ylabel('Frequency [Hz]')\n",
    "        ax.set_xlabel('Time [sec]')\n",
    "        #ax.set_ylim([3, 50])\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    fig.suptitle(fname, fontsize=30)\n",
    "print(wave.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (c:\\Users\\manabe ayumu\\.vscode\\extensions\\ms-toolsai.jupyter-2021.9.1101343141\\out\\client\\extension.js:52:301180)",
      "at w.execute (c:\\Users\\manabe ayumu\\.vscode\\extensions\\ms-toolsai.jupyter-2021.9.1101343141\\out\\client\\extension.js:52:300551)",
      "at w.start (c:\\Users\\manabe ayumu\\.vscode\\extensions\\ms-toolsai.jupyter-2021.9.1101343141\\out\\client\\extension.js:52:296215)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\manabe ayumu\\.vscode\\extensions\\ms-toolsai.jupyter-2021.9.1101343141\\out\\client\\extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (c:\\Users\\manabe ayumu\\.vscode\\extensions\\ms-toolsai.jupyter-2021.9.1101343141\\out\\client\\extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "sample = np.array([[100,1,2],[3,4,5],[6,7,8],[9,10,11]])\n",
    "freqs = np.array([60.50083182,57.10518106,53.90011352, 50.8749326])\n",
    "t = np.arange(0,3) # グラフ横軸（時間）\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.pcolormesh(t, freqs, np.abs(sample), vmin=0, shading='auto')\n",
    "ax.set_ylabel('Frequency [Hz]')\n",
    "ax.set_xlabel('Time [sec]')\n",
    "#ax.set_ylim([3, 50])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cef9e06bb236b2a8629b07e87a04b187b952a0f661eff5533360a155783f0c33"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
